{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection in Crypto (ETH Blockchain)  \n",
    "Dataset Link: https://www.kaggle.com/datasets/vagifa/ethereum-frauddetection-dataset/code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_matrix(data):\n",
    "    # Compute the correlation matrix of numeric columns\n",
    "    corr = data.select_dtypes(include='number').corr()\n",
    "\n",
    "    # Create mask to hide upper triangle\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    # Set up matplotlib figure\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    # Customize seaborn heatmap\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', mask=mask, cbar_kws={'shrink':0.8})\n",
    "\n",
    "    # Rotate x-axis labels\n",
    "    plt.xticks(rotation=80)\n",
    "\n",
    "    # Set plot title\n",
    "    plt.title(\"Correlation Matrix\", fontsize=20)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corelated(data, target_col, threshold):\n",
    "    \"\"\"\n",
    "    Finds columns in `data` with correlation >= threshold (absolute) with the target column.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pandas DataFrame\n",
    "    - target_col: string, name of the column to compare against\n",
    "    - threshold: float, minimum absolute correlation to include\n",
    "\n",
    "    Returns:\n",
    "    - pandas Series: correlation values sorted by strength\n",
    "    \"\"\"\n",
    "    # Select numeric columns only\n",
    "    numeric_data = data.select_dtypes(include='number')\n",
    "\n",
    "    # Check if the target column is numeric and in the DataFrame\n",
    "    if target_col not in numeric_data.columns:\n",
    "        raise ValueError(f\"'{target_col}' must be a numeric column in the DataFrame\")\n",
    "\n",
    "    # Compute correlation with target column\n",
    "    corrs = numeric_data.corrwith(numeric_data[target_col])\n",
    "\n",
    "    # Filter based on threshold\n",
    "    result = corrs[abs(corrs) >= threshold].drop(labels=[target_col])\n",
    "\n",
    "    return result.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_corr_pairs(df, threshold=0.3):\n",
    "    # Only use numeric columns\n",
    "    corr_matrix = df.select_dtypes(include='number').corr()\n",
    "\n",
    "    # Unstack the matrix to get pairs\n",
    "    corr_unstacked = corr_matrix.abs().unstack()\n",
    "\n",
    "    # Filter pairs above threshold but remove self-correlation (value = 1)\n",
    "    high_corr_pairs = corr_unstacked[\n",
    "        (corr_unstacked > threshold) & (corr_unstacked < 1)\n",
    "    ].drop_duplicates()\n",
    "\n",
    "    return high_corr_pairs.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corelated(df, 'FLAG', 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_highly_correlated_features(df, threshold=0.8):\n",
    "    # Step 1: Compute correlation matrix (absolute values)\n",
    "    corr_matrix = df.select_dtypes(include='number').corr().abs()\n",
    "\n",
    "    # Step 2: Get upper triangle of the matrix (no duplicates or self-correlations)\n",
    "    upper = corr_matrix.where(\n",
    "        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "    )\n",
    "\n",
    "    # Step 3: Find pairs above threshold\n",
    "    to_drop = set()\n",
    "    for col in upper.columns:\n",
    "        for row in upper.index:\n",
    "            if upper.loc[row, col] > threshold:\n",
    "                # Drop col if not already dropped; otherwise skip\n",
    "                if col not in to_drop and row not in to_drop:\n",
    "                    to_drop.add(col)\n",
    "\n",
    "    # Step 4: Drop selected columns\n",
    "    reduced_df = df.drop(columns=to_drop)\n",
    "\n",
    "    return reduced_df, list(to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML models Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup(df,target=\"FLAG\",session_id=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = df.iloc[:,1:].select_dtypes(include = ['number'])\n",
    "no_var = check.var() == 0 \n",
    "zero_var_cols = check.columns[no_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop features with Variance = 0\n",
    "data = df.drop(columns = zero_var_cols)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_, dropped_cols = drop_highly_correlated_features(data, threshold=0.5)\n",
    "data_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = data_.select_dtypes(include = ['number'])\n",
    "num_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features that have mostly 0s\n",
    "drop = []\n",
    "for i in num_data.columns[1:]:\n",
    "    if len(num_data[i].value_counts()) < 10:\n",
    "        drop.append(i)\n",
    "        print(df[i].value_counts())\n",
    "        print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['min value sent to contract',\n",
    " 'max val sent to contract',\n",
    " 'ERC20 uniq sent addr.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data.drop(columns=drop, inplace = True)\n",
    "feature = num_data.columns[1:]\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_matrix(num_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Model\n",
    "\n",
    "Class 1 represents the minority class (~22%), which could lead the model to favor predicting Class 0. To address this imbalance, SMOTE (Synthetic Minority Over-sampling Technique) should be applied to resample the training data and ensure better representation of the minority class during model learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = num_data[feature]\n",
    "y = num_data['FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def model(X, y, pipeline):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix: \\n{cm}')\n",
    "    print('\\n')\n",
    "\n",
    "    # Predict on training data\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "\n",
    "    # Accuracy scores\n",
    "    print(f\"Training accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "    print(f\"Test accuracy:     {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "    #Predict probabilities\n",
    "    y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    auc_score = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.2f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"red\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=10))\n",
    "])\n",
    "\n",
    "model(X,y,pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline([('smote', SMOTE(random_state=42)),\n",
    "                     ('scaler', StandardScaler()),\n",
    "                     ('lr', LogisticRegression(max_iter=1000))])\n",
    "\n",
    "model(X,y,pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "pipeline = Pipeline([('smote', SMOTE(random_state=42)),\n",
    "                     ('scaler', StandardScaler()),\n",
    "                     ('rf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "model(X,y,pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "XGBoost achieved the test accuracy of 95%, demonstrating strong overall performance in classifying both fraudulent and non-fraudulent cases.\n",
    "\n",
    "Based on a test dataset of 1,964 samples:\n",
    "\n",
    "* Out of 436 actual fraud cases, the model correctly identified 373 cases, achieving a recall of 86%.\n",
    "\n",
    "* Out of 416 predicted fraud cases, 373 were correct, yielding a precision of 90%.\n",
    "\n",
    "An AUC (Area Under the ROC Curve) of 0.98 indicates that the model is highly effective at distinguishing between the two classes, suggesting near-perfect separability between fraudulent and non-fraudulent transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "model(X, y, pipeline)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier  # or your model\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')  # use 'roc_auc' for AUC\n",
    "\n",
    "print(\"Cross-Validation Accuracy Scores:\", scores)\n",
    "print(\"Mean CV Accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_data = num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.set_option('display.float_format', '{:,.6f}'.format)\n",
    "\n",
    "X = logit_data[feature]\n",
    "y = logit_data['FLAG']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=109)\n",
    "\n",
    "#Logistic Model\n",
    "log_model = sm.Logit(y_train,X_train).fit()\n",
    "print(log_model.summary())\n",
    "\n",
    "#Predictation on test data\n",
    "y_pred = log_model.predict(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "X_test= X_test.copy()\n",
    "X_test.loc[:,'prediction']=0\n",
    "X_test.loc[y_pred>0.5 ,'prediction']=1\n",
    "print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test,X_test['prediction']))\n",
    "print(\"\\n\",classification_report(y_test,X_test['prediction'],digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
